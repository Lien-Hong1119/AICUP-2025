{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 路徑設定及安裝"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# !pip install git+https://github.com/openai/whisper.git",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from groq import Groq\n",
    "from pathlib import Path\n",
    "import whisperx\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm  # ← 這樣匯入的是函數，而非整個模組\n",
    "import difflib\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import whisper\n",
    "import re\n",
    "\n",
    "base_path = Path(r\"your_path\")\n",
    "WAV_Dataset = base_path / \"WAV\"\n",
    "WAV_AGAIN_Dataset = base_path / \"WAV_AGAIN\"\n",
    "submission_task1_answer_ZHEN = base_path / \"submission/task1_answer_ZHEN.txt\"\n",
    "submission_task1_answer_TWZH = base_path / \"submission/task1_answer_TWZH.txt\"\n",
    "task1_answer_timestamps = base_path / \"task1_answer_timestamps.json\"\n",
    "task1_answer_timestamps_ZH = base_path / \"task1_answer_timestamps_ZH.json\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "## task1_answer_ZHEN\n",
    "# 關通知\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## task1_answer_ZHEN"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 關通知\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# === 載入 whisperx 模型（自動語言偵測）===\n",
    "batch_size = 1\n",
    "model = whisperx.load_model(\n",
    "    \"large-v3\",\n",
    "    device=device,\n",
    "    language=None,               # 自動語言偵測，保留中英文混合\n",
    "    vad_options={\"vad\": False}   # 關閉 VAD\n",
    ")\n",
    "\n",
    "# === 開始處理 WAV 檔 ===\n",
    "with open(submission_task1_answer_ZHEN, \"w\", encoding=\"utf-8\") as fout:\n",
    "    wav_files = sorted(WAV_Dataset.glob(\"*.wav\"))\n",
    "\n",
    "    with tqdm(total=len(wav_files), desc=\"Transcribing WAV files\") as pbar:\n",
    "        for i, file in enumerate(wav_files):\n",
    "            file_id = file.stem\n",
    "            try:\n",
    "                # 自動語言辨識（中英文混合）\n",
    "                # 關通知\n",
    "                with suppress_stdout():\n",
    "                    result = model.transcribe(str(file), batch_size=batch_size)\n",
    "\n",
    "                segments = result.get(\"segments\", [])\n",
    "                full_text = \" \".join(seg[\"text\"].strip() for seg in segments).strip()\n",
    "\n",
    "                # 清理特殊 token\n",
    "                for token in [\"<|startoftranscript|>\", \"<|en|>\", \"<|zh|>\", \"<|transcribe|>\", \"<|notimestamps|>\"]:\n",
    "                    full_text = full_text.replace(token, \"\")\n",
    "                full_text = full_text.replace(\"Ġ\", \"\").strip()\n",
    "\n",
    "                # 寫入結果\n",
    "                fout.write(f\"{file_id}\\t{full_text}\\n\")\n",
    "                fout.flush()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] 處理 {file_id} 失敗：{e}\")\n",
    "                continue\n",
    "\n",
    "            # 每 10 筆更新一次進度條，最後補上餘數\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(wav_files):\n",
    "                step = 10 if (i + 1) % 10 == 0 else (len(wav_files) % 10)\n",
    "                pbar.update(step)\n",
    "\n",
    "print(f\"\\n✅ 完成轉錄（中英文混合）：共處理 {len(wav_files)} 筆，結果已儲存至：{submission_task1_answer_ZHEN}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 調整task1_answer.txt順序"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 讀取檔案（tab 分隔）\n",
    "df = pd.read_csv(submission_task1_answer_ZHEN, sep=\"\\t\", header=None, names=[\"fid\", \"text\"])\n",
    "\n",
    "# 檢查總筆數與重複 fid\n",
    "print(f\"總筆數：{len(df)}\")\n",
    "duplicates = df[df.duplicated(subset=\"fid\", keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"發現重複的 fid：\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"無重複 fid\")\n",
    "\n",
    "# 依 fid 排序並重新寫回檔案\n",
    "df_sorted = df.sort_values(by=\"fid\")\n",
    "df_sorted.to_csv(submission_task1_answer_ZHEN, sep=\"\\t\", index=False, header=False, encoding=\"utf-8\")\n",
    "print(f\"\\n已重新依 fid 排序並儲存至：{submission_task1_answer_ZHEN}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 全EN時間戳"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import whisperx\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 載入 WhisperX 模型（語音辨識）===\n",
    "batch_size = 1\n",
    "model = whisperx.load_model(\"large-v3\", device=device, language=\"en\")\n",
    "\n",
    "# === 載入英文對齊模型 ===\n",
    "align_model, metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n",
    "\n",
    "# === 開始處理 WAV 檔案並寫入詞級時間戳 ===\n",
    "with open(task1_answer_timestamps, \"w\", encoding=\"utf-8\") as fout:\n",
    "    wav_files = sorted(WAV_Dataset.glob(\"*.wav\"))\n",
    "\n",
    "    for i, file in enumerate(tqdm(wav_files, desc=\"Aligning English timestamps\")):\n",
    "        file_id = file.stem\n",
    "        try:\n",
    "            # 語音辨識\n",
    "            result = model.transcribe(str(file), batch_size=batch_size, language=\"en\")\n",
    "\n",
    "            # 對齊詞級時間戳\n",
    "            result_aligned = whisperx.align(result[\"segments\"], align_model, metadata, str(file), device=device)\n",
    "            word_segments = result_aligned.get(\"word_segments\", [])\n",
    "\n",
    "            filtered_words = []\n",
    "            skipped_words = []\n",
    "\n",
    "            for w in word_segments:\n",
    "                if \"word\" in w and \"start\" in w and \"end\" in w:\n",
    "                    filtered_words.append({\n",
    "                        \"word\": w[\"word\"],\n",
    "                        \"start\": w[\"start\"],\n",
    "                        \"end\": w[\"end\"]\n",
    "                    })\n",
    "                else:\n",
    "                    skipped_words.append(w.get(\"word\", \"<UNKNOWN>\"))\n",
    "\n",
    "            if skipped_words:\n",
    "                print(f\"[WARN] {file_id} 有 {len(skipped_words)} 個單字無法對齊時間，已略過：{skipped_words}\")\n",
    "\n",
    "            entry = {\n",
    "                \"filename\": file_id,\n",
    "                \"language\": \"en\",\n",
    "                \"words\": filtered_words\n",
    "            }\n",
    "            fout.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "            fout.flush()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 處理 {file.name} 失敗：{e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n✅ 全英文 timestamp 對齊完成，結果儲存於：{task1_answer_timestamps}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 純中文時間戳"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import whisperx\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 載入 WhisperX 中文模型與對齊器 ===\n",
    "batch_size = 1\n",
    "model_zh = whisperx.load_model(\"large-v3\", device=device, language=\"zh\")\n",
    "align_model_zh, metadata_zh = whisperx.load_align_model(language_code=\"zh\", device=device)\n",
    "\n",
    "# === 開始處理 WAV 檔案，僅針對 fid >= 80000 寫入詞級時間戳 ===\n",
    "with open(task1_answer_timestamps_ZH, \"w\", encoding=\"utf-8\") as fout:\n",
    "    wav_files = sorted(WAV_Dataset.glob(\"*.wav\"))\n",
    "\n",
    "    for file in tqdm(wav_files, desc=\"Aligning Chinese timestamps (fid ≥ 80000)\"):\n",
    "        file_id = file.stem\n",
    "\n",
    "        try:\n",
    "            fid_int = int(file_id)\n",
    "        except ValueError:\n",
    "            print(f\"[SKIP] 無效的 file_id：{file_id}\")\n",
    "            continue\n",
    "\n",
    "        if fid_int < 80000:\n",
    "            continue  # ❌ 不處理英文\n",
    "\n",
    "        try:\n",
    "            # 中文語音辨識\n",
    "            result = model_zh.transcribe(str(file), batch_size=batch_size, language=\"zh\")\n",
    "\n",
    "            # 對齊詞級時間戳\n",
    "            result_aligned = whisperx.align(result[\"segments\"], align_model_zh, metadata_zh, str(file), device=device)\n",
    "            word_segments = result_aligned.get(\"word_segments\", [])\n",
    "\n",
    "            filtered_words = []\n",
    "            skipped_words = []\n",
    "\n",
    "            for w in word_segments:\n",
    "                if \"word\" in w and \"start\" in w and \"end\" in w:\n",
    "                    filtered_words.append({\n",
    "                        \"word\": w[\"word\"],\n",
    "                        \"start\": w[\"start\"],\n",
    "                        \"end\": w[\"end\"]\n",
    "                    })\n",
    "                else:\n",
    "                    skipped_words.append(w.get(\"word\", \"<UNKNOWN>\"))\n",
    "\n",
    "            if skipped_words:\n",
    "                print(f\"[WARN] {file_id} 有 {len(skipped_words)} 個單字無法對齊時間，已略過：{skipped_words}\")\n",
    "\n",
    "            entry = {\n",
    "                \"filename\": file_id,\n",
    "                \"language\": \"zh\",\n",
    "                \"words\": filtered_words\n",
    "            }\n",
    "\n",
    "            fout.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "            fout.flush()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 處理 {file.name} 失敗：{e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n✅ 只針對 fid ≥ 80000 的檔案完成中文 timestamp 對齊，結果儲存於：{task1_answer_timestamps_ZH}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 特殊無法辨別的，再辨別一次"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ========== 讀取原始 ZHEN 檔案 ==========\n",
    "# === 載入 WhisperX 模型（語音辨識）===\n",
    "batch_size = 1\n",
    "model = whisperx.load_model(\"large-v3\", device=device, language=\"zh\")\n",
    "\n",
    "result_dict = {}\n",
    "invalid_lines = []\n",
    "\n",
    "\n",
    "with open(submission_task1_answer_ZHEN, \"r\", encoding=\"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        parts = line.strip().split(\"\\t\", maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            file_id, text = parts\n",
    "            result_dict[file_id] = text\n",
    "        else:\n",
    "            invalid_lines.append(line.strip())\n",
    "\n",
    "# ========== 重新處理 WAV_AGAIN ==========\n",
    "wav_again_files = sorted(WAV_AGAIN_Dataset.glob(\"*.wav\"))\n",
    "updated_file_ids = []\n",
    "updated_log = {}\n",
    "\n",
    "print(f\"\\n🔁 重新處理 {len(wav_again_files)} 筆 WAV_AGAIN 檔案...\")\n",
    "\n",
    "with tqdm(total=len(wav_again_files), desc=\"Re-transcribing (WAV_AGAIN)\") as pbar:\n",
    "    for file in wav_again_files:\n",
    "        file_id = file.stem\n",
    "        try:\n",
    "            with suppress_stdout():\n",
    "                result = model.transcribe(str(file), batch_size=batch_size)\n",
    "\n",
    "            segments = result.get(\"segments\", [])\n",
    "            full_text = \" \".join(seg[\"text\"].strip() for seg in segments).strip()\n",
    "\n",
    "            for token in [\"<|startoftranscript|>\", \"<|en|>\", \"<|zh|>\", \"<|transcribe|>\", \"<|notimestamps|>\"]:\n",
    "                full_text = full_text.replace(token, \"\")\n",
    "            full_text = full_text.replace(\"Ġ\", \"\").strip()\n",
    "\n",
    "            old_text = result_dict.get(file_id, \"\")\n",
    "            result_dict[file_id] = full_text\n",
    "            updated_file_ids.append(file_id)\n",
    "            updated_log[file_id] = {\n",
    "                \"before\": old_text,\n",
    "                \"after\": full_text\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] WAV_AGAIN 處理 {file_id} 失敗：{e}\")\n",
    "            continue\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "# ========== 寫回更新後的 ZHEN 檔案 ==========\n",
    "with open(submission_task1_answer_ZHEN, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for file_id in sorted(result_dict.keys()):\n",
    "        fout.write(f\"{file_id}\\t{result_dict[file_id]}\\n\")\n",
    "\n",
    "# ========== 印出變更紀錄 ==========\n",
    "if updated_log:\n",
    "    print(\"\\n🔁 以下檔案已重新轉錄並更新：\")\n",
    "    for fid in sorted(updated_log.keys()):\n",
    "        before = updated_log[fid][\"before\"]\n",
    "        after = updated_log[fid][\"after\"]\n",
    "        print(f\" - {fid}\")\n",
    "        print(f\"   🟡 Before: {before}\")\n",
    "        print(f\"   🟢 After : {after}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 沒有任何檔案被更新。\")\n",
    "\n",
    "# ========== 顯示格式錯誤行（若有） ==========\n",
    "if invalid_lines:\n",
    "    print(\"\\n以下行無法解析（缺少TAB或欄位不完整），請檢查原始檔案：\")\n",
    "    for line in invalid_lines:\n",
    "        print(\" -\", line)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 清洗文字，將簡體轉繁體+轉換特殊文字"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from opencc import OpenCC\n",
    "\n",
    "# 檔案路徑\n",
    "input_path = submission_task1_answer_ZHEN\n",
    "output_path = submission_task1_answer_TWZH\n",
    "\n",
    "# Step 1: 簡體轉繁體\n",
    "cc = OpenCC('s2t')\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as fin:\n",
    "    lines = fin.readlines()\n",
    "\n",
    "converted_lines = [cc.convert(line) for line in lines]\n",
    "\n",
    "# Step 2: 常見的簡體轉繁體錯誤\n",
    "custom_replacements = {\n",
    "    \"牀\": \"床\",\n",
    "    \"喫\": \"吃\",\n",
    "    \"台\": \"臺\",\n",
    "}\n",
    "\n",
    "# Step 3: 替換並記錄 log\n",
    "final_lines = []\n",
    "log = {}\n",
    "\n",
    "for line in converted_lines:\n",
    "    if \"\\t\" not in line:\n",
    "        final_lines.append(line)\n",
    "        continue\n",
    "\n",
    "    fid, sentence = line.strip().split(\"\\t\", maxsplit=1)\n",
    "    original_sentence = sentence\n",
    "    changes = []\n",
    "\n",
    "    for wrong, correct in custom_replacements.items():\n",
    "        if wrong in sentence:\n",
    "            sentence = sentence.replace(wrong, correct)\n",
    "            changes.append((wrong, correct))\n",
    "\n",
    "    final_lines.append(f\"{fid}\\t{sentence}\\n\")\n",
    "\n",
    "    if changes:\n",
    "        log[fid] = changes\n",
    "\n",
    "# Step 4: 寫回轉繁體 + 替換後的最終版本\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.writelines(final_lines)\n",
    "\n",
    "# Step 5: 印出替換 log\n",
    "if log:\n",
    "    print(\"修正記錄：\")\n",
    "    for fid in sorted(log.keys()):\n",
    "        print(f\"- {fid}\")\n",
    "        for wrong, correct in log[fid]:\n",
    "            print(f\"  ⮕ 替換：{wrong} ➜ {correct}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 把重複字的改掉"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# 設定最大重複次數\n",
    "MAX_REPEATS = 5\n",
    "\n",
    "# 限制詞語重複次數\n",
    "def limit_repeated_tokens(text, max_repeats=MAX_REPEATS):\n",
    "    # 限制單字（例如：啊啊啊啊啊啊 ➜ 啊啊啊啊啊）\n",
    "    text = re.sub(r'(.)\\1{' + str(max_repeats) + r',}', lambda m: m.group(1) * max_repeats, text)\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(\\S{2,10}?)(\\1){' + str(max_repeats) + r',}',\n",
    "        lambda m: m.group(1) * max_repeats,\n",
    "        text\n",
    "    )\n",
    "\n",
    "    return text\n",
    "\n",
    "# 讀取 TWZH 檔案\n",
    "with open(submission_task1_answer_TWZH, \"r\", encoding=\"utf-8\") as fin:\n",
    "    lines = fin.readlines()\n",
    "\n",
    "# 處理每一行，並記錄修改 log\n",
    "processed_lines = []\n",
    "mod_log = {}\n",
    "\n",
    "for line in lines:\n",
    "    if \"\\t\" not in line:\n",
    "        processed_lines.append(line)\n",
    "        continue\n",
    "\n",
    "    fid, sentence = line.strip().split(\"\\t\", maxsplit=1)\n",
    "    cleaned_sentence = limit_repeated_tokens(sentence)\n",
    "\n",
    "    if cleaned_sentence != sentence:\n",
    "        mod_log[fid] = {\n",
    "            \"before\": sentence,\n",
    "            \"after\": cleaned_sentence\n",
    "        }\n",
    "\n",
    "    processed_lines.append(f\"{fid}\\t{cleaned_sentence}\\n\")\n",
    "\n",
    "# 寫回 TWZH\n",
    "with open(submission_task1_answer_TWZH, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.writelines(processed_lines)\n",
    "\n",
    "# 印出修改紀錄\n",
    "if mod_log:\n",
    "    print(\"以下行已進行重複字元/詞語壓縮：\")\n",
    "    for fid in sorted(mod_log.keys()):\n",
    "        print(f\"- {fid}\")\n",
    "        print(f\"  🟡 Before: {mod_log[fid]['before']}\")\n",
    "        print(f\"  🟢 After : {mod_log[fid]['after']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}

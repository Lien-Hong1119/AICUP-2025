{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## è·¯å¾‘è¨­å®šåŠå®‰è£"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# !pip install git+https://github.com/openai/whisper.git",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from groq import Groq\n",
    "from pathlib import Path\n",
    "import whisperx\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm  # â† é€™æ¨£åŒ¯å…¥çš„æ˜¯å‡½æ•¸ï¼Œè€Œéæ•´å€‹æ¨¡çµ„\n",
    "import difflib\n",
    "import re\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import whisper\n",
    "import re\n",
    "\n",
    "base_path = Path(r\"your_path\")\n",
    "WAV_Dataset = base_path / \"WAV\"\n",
    "WAV_AGAIN_Dataset = base_path / \"WAV_AGAIN\"\n",
    "submission_task1_answer_ZHEN = base_path / \"submission/task1_answer_ZHEN.txt\"\n",
    "submission_task1_answer_TWZH = base_path / \"submission/task1_answer_TWZH.txt\"\n",
    "task1_answer_timestamps = base_path / \"task1_answer_timestamps.json\"\n",
    "task1_answer_timestamps_ZH = base_path / \"task1_answer_timestamps_ZH.json\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "## task1_answer_ZHEN\n",
    "# é—œé€šçŸ¥\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## task1_answer_ZHEN"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# é—œé€šçŸ¥\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        try:\n",
    "            sys.stdout = devnull\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# === è¼‰å…¥ whisperx æ¨¡å‹ï¼ˆè‡ªå‹•èªè¨€åµæ¸¬ï¼‰===\n",
    "batch_size = 1\n",
    "model = whisperx.load_model(\n",
    "    \"large-v3\",\n",
    "    device=device,\n",
    "    language=None,               # è‡ªå‹•èªè¨€åµæ¸¬ï¼Œä¿ç•™ä¸­è‹±æ–‡æ··åˆ\n",
    "    vad_options={\"vad\": False}   # é—œé–‰ VAD\n",
    ")\n",
    "\n",
    "# === é–‹å§‹è™•ç† WAV æª” ===\n",
    "with open(submission_task1_answer_ZHEN, \"w\", encoding=\"utf-8\") as fout:\n",
    "    wav_files = sorted(WAV_Dataset.glob(\"*.wav\"))\n",
    "\n",
    "    with tqdm(total=len(wav_files), desc=\"Transcribing WAV files\") as pbar:\n",
    "        for i, file in enumerate(wav_files):\n",
    "            file_id = file.stem\n",
    "            try:\n",
    "                # è‡ªå‹•èªè¨€è¾¨è­˜ï¼ˆä¸­è‹±æ–‡æ··åˆï¼‰\n",
    "                # é—œé€šçŸ¥\n",
    "                with suppress_stdout():\n",
    "                    result = model.transcribe(str(file), batch_size=batch_size)\n",
    "\n",
    "                segments = result.get(\"segments\", [])\n",
    "                full_text = \" \".join(seg[\"text\"].strip() for seg in segments).strip()\n",
    "\n",
    "                # æ¸…ç†ç‰¹æ®Š token\n",
    "                for token in [\"<|startoftranscript|>\", \"<|en|>\", \"<|zh|>\", \"<|transcribe|>\", \"<|notimestamps|>\"]:\n",
    "                    full_text = full_text.replace(token, \"\")\n",
    "                full_text = full_text.replace(\"Ä \", \"\").strip()\n",
    "\n",
    "                # å¯«å…¥çµæœ\n",
    "                fout.write(f\"{file_id}\\t{full_text}\\n\")\n",
    "                fout.flush()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] è™•ç† {file_id} å¤±æ•—ï¼š{e}\")\n",
    "                continue\n",
    "\n",
    "            # æ¯ 10 ç­†æ›´æ–°ä¸€æ¬¡é€²åº¦æ¢ï¼Œæœ€å¾Œè£œä¸Šé¤˜æ•¸\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(wav_files):\n",
    "                step = 10 if (i + 1) % 10 == 0 else (len(wav_files) % 10)\n",
    "                pbar.update(step)\n",
    "\n",
    "print(f\"\\nâœ… å®Œæˆè½‰éŒ„ï¼ˆä¸­è‹±æ–‡æ··åˆï¼‰ï¼šå…±è™•ç† {len(wav_files)} ç­†ï¼Œçµæœå·²å„²å­˜è‡³ï¼š{submission_task1_answer_ZHEN}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## èª¿æ•´task1_answer.txté †åº"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# è®€å–æª”æ¡ˆï¼ˆtab åˆ†éš”ï¼‰\n",
    "df = pd.read_csv(submission_task1_answer_ZHEN, sep=\"\\t\", header=None, names=[\"fid\", \"text\"])\n",
    "\n",
    "# æª¢æŸ¥ç¸½ç­†æ•¸èˆ‡é‡è¤‡ fid\n",
    "print(f\"ç¸½ç­†æ•¸ï¼š{len(df)}\")\n",
    "duplicates = df[df.duplicated(subset=\"fid\", keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"ç™¼ç¾é‡è¤‡çš„ fidï¼š\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"ç„¡é‡è¤‡ fid\")\n",
    "\n",
    "# ä¾ fid æ’åºä¸¦é‡æ–°å¯«å›æª”æ¡ˆ\n",
    "df_sorted = df.sort_values(by=\"fid\")\n",
    "df_sorted.to_csv(submission_task1_answer_ZHEN, sep=\"\\t\", index=False, header=False, encoding=\"utf-8\")\n",
    "print(f\"\\nå·²é‡æ–°ä¾ fid æ’åºä¸¦å„²å­˜è‡³ï¼š{submission_task1_answer_ZHEN}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## å…¨ENæ™‚é–“æˆ³"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import whisperx\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === è¼‰å…¥ WhisperX æ¨¡å‹ï¼ˆèªéŸ³è¾¨è­˜ï¼‰===\n",
    "batch_size = 1\n",
    "model = whisperx.load_model(\"large-v3\", device=device, language=\"en\")\n",
    "\n",
    "# === è¼‰å…¥è‹±æ–‡å°é½Šæ¨¡å‹ ===\n",
    "align_model, metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n",
    "\n",
    "# === é–‹å§‹è™•ç† WAV æª”æ¡ˆä¸¦å¯«å…¥è©ç´šæ™‚é–“æˆ³ ===\n",
    "with open(task1_answer_timestamps, \"w\", encoding=\"utf-8\") as fout:\n",
    "    wav_files = sorted(WAV_Dataset.glob(\"*.wav\"))\n",
    "\n",
    "    for i, file in enumerate(tqdm(wav_files, desc=\"Aligning English timestamps\")):\n",
    "        file_id = file.stem\n",
    "        try:\n",
    "            # èªéŸ³è¾¨è­˜\n",
    "            result = model.transcribe(str(file), batch_size=batch_size, language=\"en\")\n",
    "\n",
    "            # å°é½Šè©ç´šæ™‚é–“æˆ³\n",
    "            result_aligned = whisperx.align(result[\"segments\"], align_model, metadata, str(file), device=device)\n",
    "            word_segments = result_aligned.get(\"word_segments\", [])\n",
    "\n",
    "            filtered_words = []\n",
    "            skipped_words = []\n",
    "\n",
    "            for w in word_segments:\n",
    "                if \"word\" in w and \"start\" in w and \"end\" in w:\n",
    "                    filtered_words.append({\n",
    "                        \"word\": w[\"word\"],\n",
    "                        \"start\": w[\"start\"],\n",
    "                        \"end\": w[\"end\"]\n",
    "                    })\n",
    "                else:\n",
    "                    skipped_words.append(w.get(\"word\", \"<UNKNOWN>\"))\n",
    "\n",
    "            if skipped_words:\n",
    "                print(f\"[WARN] {file_id} æœ‰ {len(skipped_words)} å€‹å–®å­—ç„¡æ³•å°é½Šæ™‚é–“ï¼Œå·²ç•¥éï¼š{skipped_words}\")\n",
    "\n",
    "            entry = {\n",
    "                \"filename\": file_id,\n",
    "                \"language\": \"en\",\n",
    "                \"words\": filtered_words\n",
    "            }\n",
    "            fout.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "            fout.flush()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] è™•ç† {file.name} å¤±æ•—ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\nâœ… å…¨è‹±æ–‡ timestamp å°é½Šå®Œæˆï¼Œçµæœå„²å­˜æ–¼ï¼š{task1_answer_timestamps}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ç´”ä¸­æ–‡æ™‚é–“æˆ³"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import whisperx\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === è¼‰å…¥ WhisperX ä¸­æ–‡æ¨¡å‹èˆ‡å°é½Šå™¨ ===\n",
    "batch_size = 1\n",
    "model_zh = whisperx.load_model(\"large-v3\", device=device, language=\"zh\")\n",
    "align_model_zh, metadata_zh = whisperx.load_align_model(language_code=\"zh\", device=device)\n",
    "\n",
    "# === é–‹å§‹è™•ç† WAV æª”æ¡ˆï¼Œåƒ…é‡å° fid >= 80000 å¯«å…¥è©ç´šæ™‚é–“æˆ³ ===\n",
    "with open(task1_answer_timestamps_ZH, \"w\", encoding=\"utf-8\") as fout:\n",
    "    wav_files = sorted(WAV_Dataset.glob(\"*.wav\"))\n",
    "\n",
    "    for file in tqdm(wav_files, desc=\"Aligning Chinese timestamps (fid â‰¥ 80000)\"):\n",
    "        file_id = file.stem\n",
    "\n",
    "        try:\n",
    "            fid_int = int(file_id)\n",
    "        except ValueError:\n",
    "            print(f\"[SKIP] ç„¡æ•ˆçš„ file_idï¼š{file_id}\")\n",
    "            continue\n",
    "\n",
    "        if fid_int < 80000:\n",
    "            continue  # âŒ ä¸è™•ç†è‹±æ–‡\n",
    "\n",
    "        try:\n",
    "            # ä¸­æ–‡èªéŸ³è¾¨è­˜\n",
    "            result = model_zh.transcribe(str(file), batch_size=batch_size, language=\"zh\")\n",
    "\n",
    "            # å°é½Šè©ç´šæ™‚é–“æˆ³\n",
    "            result_aligned = whisperx.align(result[\"segments\"], align_model_zh, metadata_zh, str(file), device=device)\n",
    "            word_segments = result_aligned.get(\"word_segments\", [])\n",
    "\n",
    "            filtered_words = []\n",
    "            skipped_words = []\n",
    "\n",
    "            for w in word_segments:\n",
    "                if \"word\" in w and \"start\" in w and \"end\" in w:\n",
    "                    filtered_words.append({\n",
    "                        \"word\": w[\"word\"],\n",
    "                        \"start\": w[\"start\"],\n",
    "                        \"end\": w[\"end\"]\n",
    "                    })\n",
    "                else:\n",
    "                    skipped_words.append(w.get(\"word\", \"<UNKNOWN>\"))\n",
    "\n",
    "            if skipped_words:\n",
    "                print(f\"[WARN] {file_id} æœ‰ {len(skipped_words)} å€‹å–®å­—ç„¡æ³•å°é½Šæ™‚é–“ï¼Œå·²ç•¥éï¼š{skipped_words}\")\n",
    "\n",
    "            entry = {\n",
    "                \"filename\": file_id,\n",
    "                \"language\": \"zh\",\n",
    "                \"words\": filtered_words\n",
    "            }\n",
    "\n",
    "            fout.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "            fout.flush()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] è™•ç† {file.name} å¤±æ•—ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\nâœ… åªé‡å° fid â‰¥ 80000 çš„æª”æ¡ˆå®Œæˆä¸­æ–‡ timestamp å°é½Šï¼Œçµæœå„²å­˜æ–¼ï¼š{task1_answer_timestamps_ZH}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ç‰¹æ®Šç„¡æ³•è¾¨åˆ¥çš„ï¼Œå†è¾¨åˆ¥ä¸€æ¬¡"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ========== è®€å–åŸå§‹ ZHEN æª”æ¡ˆ ==========\n",
    "# === è¼‰å…¥ WhisperX æ¨¡å‹ï¼ˆèªéŸ³è¾¨è­˜ï¼‰===\n",
    "batch_size = 1\n",
    "model = whisperx.load_model(\"large-v3\", device=device, language=\"zh\")\n",
    "\n",
    "result_dict = {}\n",
    "invalid_lines = []\n",
    "\n",
    "\n",
    "with open(submission_task1_answer_ZHEN, \"r\", encoding=\"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        parts = line.strip().split(\"\\t\", maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            file_id, text = parts\n",
    "            result_dict[file_id] = text\n",
    "        else:\n",
    "            invalid_lines.append(line.strip())\n",
    "\n",
    "# ========== é‡æ–°è™•ç† WAV_AGAIN ==========\n",
    "wav_again_files = sorted(WAV_AGAIN_Dataset.glob(\"*.wav\"))\n",
    "updated_file_ids = []\n",
    "updated_log = {}\n",
    "\n",
    "print(f\"\\nğŸ” é‡æ–°è™•ç† {len(wav_again_files)} ç­† WAV_AGAIN æª”æ¡ˆ...\")\n",
    "\n",
    "with tqdm(total=len(wav_again_files), desc=\"Re-transcribing (WAV_AGAIN)\") as pbar:\n",
    "    for file in wav_again_files:\n",
    "        file_id = file.stem\n",
    "        try:\n",
    "            with suppress_stdout():\n",
    "                result = model.transcribe(str(file), batch_size=batch_size)\n",
    "\n",
    "            segments = result.get(\"segments\", [])\n",
    "            full_text = \" \".join(seg[\"text\"].strip() for seg in segments).strip()\n",
    "\n",
    "            for token in [\"<|startoftranscript|>\", \"<|en|>\", \"<|zh|>\", \"<|transcribe|>\", \"<|notimestamps|>\"]:\n",
    "                full_text = full_text.replace(token, \"\")\n",
    "            full_text = full_text.replace(\"Ä \", \"\").strip()\n",
    "\n",
    "            old_text = result_dict.get(file_id, \"\")\n",
    "            result_dict[file_id] = full_text\n",
    "            updated_file_ids.append(file_id)\n",
    "            updated_log[file_id] = {\n",
    "                \"before\": old_text,\n",
    "                \"after\": full_text\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] WAV_AGAIN è™•ç† {file_id} å¤±æ•—ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "# ========== å¯«å›æ›´æ–°å¾Œçš„ ZHEN æª”æ¡ˆ ==========\n",
    "with open(submission_task1_answer_ZHEN, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for file_id in sorted(result_dict.keys()):\n",
    "        fout.write(f\"{file_id}\\t{result_dict[file_id]}\\n\")\n",
    "\n",
    "# ========== å°å‡ºè®Šæ›´ç´€éŒ„ ==========\n",
    "if updated_log:\n",
    "    print(\"\\nğŸ” ä»¥ä¸‹æª”æ¡ˆå·²é‡æ–°è½‰éŒ„ä¸¦æ›´æ–°ï¼š\")\n",
    "    for fid in sorted(updated_log.keys()):\n",
    "        before = updated_log[fid][\"before\"]\n",
    "        after = updated_log[fid][\"after\"]\n",
    "        print(f\" - {fid}\")\n",
    "        print(f\"   ğŸŸ¡ Before: {before}\")\n",
    "        print(f\"   ğŸŸ¢ After : {after}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ æ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æ›´æ–°ã€‚\")\n",
    "\n",
    "# ========== é¡¯ç¤ºæ ¼å¼éŒ¯èª¤è¡Œï¼ˆè‹¥æœ‰ï¼‰ ==========\n",
    "if invalid_lines:\n",
    "    print(\"\\nä»¥ä¸‹è¡Œç„¡æ³•è§£æï¼ˆç¼ºå°‘TABæˆ–æ¬„ä½ä¸å®Œæ•´ï¼‰ï¼Œè«‹æª¢æŸ¥åŸå§‹æª”æ¡ˆï¼š\")\n",
    "    for line in invalid_lines:\n",
    "        print(\" -\", line)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ¸…æ´—æ–‡å­—ï¼Œå°‡ç°¡é«”è½‰ç¹é«”+è½‰æ›ç‰¹æ®Šæ–‡å­—"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from opencc import OpenCC\n",
    "\n",
    "# æª”æ¡ˆè·¯å¾‘\n",
    "input_path = submission_task1_answer_ZHEN\n",
    "output_path = submission_task1_answer_TWZH\n",
    "\n",
    "# Step 1: ç°¡é«”è½‰ç¹é«”\n",
    "cc = OpenCC('s2t')\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as fin:\n",
    "    lines = fin.readlines()\n",
    "\n",
    "converted_lines = [cc.convert(line) for line in lines]\n",
    "\n",
    "# Step 2: å¸¸è¦‹çš„ç°¡é«”è½‰ç¹é«”éŒ¯èª¤\n",
    "custom_replacements = {\n",
    "    \"ç‰€\": \"åºŠ\",\n",
    "    \"å–«\": \"åƒ\",\n",
    "    \"å°\": \"è‡º\",\n",
    "}\n",
    "\n",
    "# Step 3: æ›¿æ›ä¸¦è¨˜éŒ„ log\n",
    "final_lines = []\n",
    "log = {}\n",
    "\n",
    "for line in converted_lines:\n",
    "    if \"\\t\" not in line:\n",
    "        final_lines.append(line)\n",
    "        continue\n",
    "\n",
    "    fid, sentence = line.strip().split(\"\\t\", maxsplit=1)\n",
    "    original_sentence = sentence\n",
    "    changes = []\n",
    "\n",
    "    for wrong, correct in custom_replacements.items():\n",
    "        if wrong in sentence:\n",
    "            sentence = sentence.replace(wrong, correct)\n",
    "            changes.append((wrong, correct))\n",
    "\n",
    "    final_lines.append(f\"{fid}\\t{sentence}\\n\")\n",
    "\n",
    "    if changes:\n",
    "        log[fid] = changes\n",
    "\n",
    "# Step 4: å¯«å›è½‰ç¹é«” + æ›¿æ›å¾Œçš„æœ€çµ‚ç‰ˆæœ¬\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.writelines(final_lines)\n",
    "\n",
    "# Step 5: å°å‡ºæ›¿æ› log\n",
    "if log:\n",
    "    print(\"ä¿®æ­£è¨˜éŒ„ï¼š\")\n",
    "    for fid in sorted(log.keys()):\n",
    "        print(f\"- {fid}\")\n",
    "        for wrong, correct in log[fid]:\n",
    "            print(f\"  â®• æ›¿æ›ï¼š{wrong} âœ {correct}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æŠŠé‡è¤‡å­—çš„æ”¹æ‰"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# è¨­å®šæœ€å¤§é‡è¤‡æ¬¡æ•¸\n",
    "MAX_REPEATS = 5\n",
    "\n",
    "# é™åˆ¶è©èªé‡è¤‡æ¬¡æ•¸\n",
    "def limit_repeated_tokens(text, max_repeats=MAX_REPEATS):\n",
    "    # é™åˆ¶å–®å­—ï¼ˆä¾‹å¦‚ï¼šå•Šå•Šå•Šå•Šå•Šå•Š âœ å•Šå•Šå•Šå•Šå•Šï¼‰\n",
    "    text = re.sub(r'(.)\\1{' + str(max_repeats) + r',}', lambda m: m.group(1) * max_repeats, text)\n",
    "\n",
    "    text = re.sub(\n",
    "        r'(\\S{2,10}?)(\\1){' + str(max_repeats) + r',}',\n",
    "        lambda m: m.group(1) * max_repeats,\n",
    "        text\n",
    "    )\n",
    "\n",
    "    return text\n",
    "\n",
    "# è®€å– TWZH æª”æ¡ˆ\n",
    "with open(submission_task1_answer_TWZH, \"r\", encoding=\"utf-8\") as fin:\n",
    "    lines = fin.readlines()\n",
    "\n",
    "# è™•ç†æ¯ä¸€è¡Œï¼Œä¸¦è¨˜éŒ„ä¿®æ”¹ log\n",
    "processed_lines = []\n",
    "mod_log = {}\n",
    "\n",
    "for line in lines:\n",
    "    if \"\\t\" not in line:\n",
    "        processed_lines.append(line)\n",
    "        continue\n",
    "\n",
    "    fid, sentence = line.strip().split(\"\\t\", maxsplit=1)\n",
    "    cleaned_sentence = limit_repeated_tokens(sentence)\n",
    "\n",
    "    if cleaned_sentence != sentence:\n",
    "        mod_log[fid] = {\n",
    "            \"before\": sentence,\n",
    "            \"after\": cleaned_sentence\n",
    "        }\n",
    "\n",
    "    processed_lines.append(f\"{fid}\\t{cleaned_sentence}\\n\")\n",
    "\n",
    "# å¯«å› TWZH\n",
    "with open(submission_task1_answer_TWZH, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.writelines(processed_lines)\n",
    "\n",
    "# å°å‡ºä¿®æ”¹ç´€éŒ„\n",
    "if mod_log:\n",
    "    print(\"ä»¥ä¸‹è¡Œå·²é€²è¡Œé‡è¤‡å­—å…ƒ/è©èªå£“ç¸®ï¼š\")\n",
    "    for fid in sorted(mod_log.keys()):\n",
    "        print(f\"- {fid}\")\n",
    "        print(f\"  ğŸŸ¡ Before: {mod_log[fid]['before']}\")\n",
    "        print(f\"  ğŸŸ¢ After : {mod_log[fid]['after']}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
